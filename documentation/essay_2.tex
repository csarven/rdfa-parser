%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Thin Sectioned Essay
% LaTeX Template
% Version 1.0 (3/8/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original Author:
% Nicolas Diaz (nsdiaz@uc.cl) with extensive modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[hidelinks, a4paper, 11pt]{article} % Font size (can be 10pt, 11pt or 12pt) and paper size (remove a4paper for US letter paper)

\usepackage[protrusion=true,expansion=true]{microtype} % Better typography
\usepackage{graphicx} % Required for including pictures
\usepackage{wrapfig} % Allows in-line images

\usepackage{hyperref} % use links for ToC, etc.


\usepackage{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Required for accented characters
\linespread{1.05} % Change line spacing here, Palatino benefits from a slight increase by default

\makeatletter
\renewcommand\@biblabel[1]{\textbf{#1.}} % Change the square brackets for each bibliography item from '[1]' to '1.'
\renewcommand{\@listI}{\itemsep=0pt} % Reduce the space between items in the itemize and enumerate environments and the bibliography

\renewcommand{\maketitle}{ % Customize the title - do not edit title and author name here, see the TITLE block below
\begin{flushright} % Right align
{\LARGE\@title} % Increase the font size of the title

\vspace{50pt} % Some vertical space between the title and author name

{\large\@author} % Author name
\\\@date % Date

\vspace{40pt} % Some vertical space between the author block and abstract
\end{flushright}
}


%----------------------------------------------------------------------------------------
%	TITLE
%----------------------------------------------------------------------------------------

\title{\textbf{RDFa Crawler}\\ % Title
Webcrawler inklusive RDFa parsing funktion} % Subtitle

\author{\textsc{Stefan Achm\"uller, Roland Gritzer, Mathias Gschwandtner} % Author
\\{\textit{Universit\"at Innsbruck}}} % Institution

\date{\today} % Date

%----------------------------------------------------------------------------------------

\begin{document}
\maketitle % Print the title section


%----------------------------------------------------------------------------------------
%	ABSTRACT, KEYWORDS AND TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

\renewcommand{\abstractname}{Zusammenfassung} % Uncomment to change the name of the abstract to something else

\begin{abstract}
Enabling to scrap the world wide web for RDFa data. Give a URL to start from, furthermore black- and whitelisting is possible. DRFa data, integrated within html documents, is generated by applying rdfa.info sequence. RDFa data is annotated by the RDF n-triple format.
\end{abstract}

\hspace*{3,6mm}\textit{Schl\"usselw\"orter:} webcrawler, parser, rdfa % Keywords

\vspace{30pt} % Some vertical space between the abstract and first section

\renewcommand{\contentsname}{Inhaltsangabe}

\tableofcontents
\newpage

% GRADING ASPECT
% Result of written Report:
% 	2-6 pages
% 	Problem definition (what and why is it relevant?)
% 	Methodology (how did we solve?)
% 	Outcome (result of our work incl. Readme.md)

% Inline image example
% \begin{wrapfigure}{l}{0.4\textwidth} 
% \begin{center}
% \includegraphics[width=0.38\textwidth]{fish.png}
% \end{center}
% \caption{Fish}
% \end{wrapfigure}


%----------------------------------------------------------------------------------------
%	ESSAY BODY
%----------------------------------------------------------------------------------------

\section{Problem Definition}

Mit der historischen Entwicklung des Internets wurden immer wieder Techniken eingef\"uhrt, die den Datenaustausch zwischen Rechnern vereinfachen. W\"ahrend im klassischen Internet, auch Web 1.0 (URL, HTTP, HTML, etc.) genannt, der Fokus auf dem Aufbau und Transport der Daten liegt, betrachtet der Ansatz "Semantic Web" m\"ogliche Interpretationen der Daten. Dies wird auch Web 3.0 genannt und ermöglicht eine vereinfachte Abarbeitung von Aufgaben, basierend auf Internetdaten. So kann zum Beispiel unterschieden werden, ob das Wort "Bremen" auf einer bestimmten Webseite sich entweder auf eine deutsche Stadt, einen Familiennamen oder einem sonstigen Namen bezieht. Die Kerneigenschaft des "Semantic Web" stellt die Universalit\"at der Relationten, sowie die maschinelle Interpretationsmöglichkeit der Informationen dar. Dies bedeutet, dass prinzipiell alle Informationsobjekte miteinander verkn\"upft werden können um Wissen zu repr\"asentieren und verarbeiten \cite{berners2001semantic}. \\

Um Daten mit diesen Metainformationen anzureichern, wurden diverse Annotationstypen eingef\"uhrt. Neben JSON-LD und Microdata, bietet sich hierfür das "Resource Description Frameworks" (RDF) an. Ziel dieser Arbeit ist die Erstellung einer Programmierbibliothek für den JavaScript basierten "Node Package Manager" (npm) zum automatischen extrahieren von kontext spezifischen Informationen, Schema.org Vokabular annotiert mittels RDFa Syntax (W3C Standard Annotation f\"ur RDF), welche in XHTML Webseiten eingebettet sind \cite{guha2016schema}, \cite{halb2008building}.

\subsection{RDFa annotierte Information}

RDF definiert eine Schnittstelle f\"ur diverse Anotationen zur Darstellung von schemantischen Informationen. Zu diesem geh\"oren die schematische Darstellung von Informationen als Graphen. Ein Graph ist hierbei eine Menge von Triplen, welche einzelne Informationen repr\"asentieren. Ein Triple besteht jeweils aus drei verschiednenen Knoten, die in folgender Reihe definiert sind. 

\begin{itemize}
\item \textbf{Subjekt} der Information (z.B. "Hannes").
\item \textbf{Pr\"adikat} des zugeordnenten Triples (z.B. "wohnt in").
\item \textbf{Objekt} des zugeordnenten Triples  (z.B. "Innsbruck").
\end{itemize}

Jeder Knoten ist entweder ein "International Resource Identifier" (IRI), oder ein "Blank Node", welcher typischerweise als einmalige Zeichenketten (String) dargestellt wird \cite{adida2008rdfa}. \\

Teilziel der Arbeit ist die Filtern von RDFa annotierten Information von Dokumenten im XHTML Format. Der implementierte Prozess der erstellung eines RDF Graphen basiert auf der "RDFa Core Sequence" \cite{rdfaSequence}.

\subsection{Webcrawler}

Der zweite Teil der Arbeit, bezieht sich auf den Bezug von XHTML formatierten Dokumenten, welche RDFa annotierte Information enthalten. Mittels der Methode eines Webcrawlers wird auf im Internet zugreifbare Daten automatisch zugegriffen. Dabei definiert der Benutzer einen Startpunkt, ein "Uniform Resource Locater" (URL), auf den dieser Zugriff hat. Ausgehend von dieser Resource, typischerweise ein XHTML Dokument, werden weiterf\"uhrende URLs durchsucht. Wie diese Durchsuchung im Einzelnen abl\"auft, zum Beispiel welche Datenformate nicht durchsucht werden sollten, wird vom Benutzer festgelegt \cite{pinkerton2000webcrawler}. \\

Teilziel der Arbeit ist der Zugriff auf zusammenh\"angende XHTML formatierten Daten, ausgehend von einer festgelegten URL.


%------------------------------------------------

\section{Methodologie}

Nach der Definition der Aufgabenstellung, wurden die Schritte zur Probleml\"osung, inklusive einem groben Zeitplan, erstellt. Zum einen dient diese Strukturierung zur leichteren Abgrenzung von Teilproblemen und deren Bearbeitung einzelner Teammitglieder, sowie der Einhaltung strikter Deadlines.

\subsection{Recherche und Setup}

Die Einarbeitung in die Basisthemen der Arbeit wurde gemeinsam im Team vorgenommen. Folgende Themen und deren Schwerpunkte wurden recherchiert.

\begin{itemize}
\item \textbf{JavaScript, Node und npm} - verwendete Programmiersprache, serverseitiges Framework und dazugeh\"orirger Packetverwaltung.
\item \textbf{Schema.org und RDFa} - verwendetes Vokabular und Annotation der Daten.
\end{itemize}

Im Anschluss wurde mittels Node ein lokaler Server für Test- und Pr\"asentationszwecke erstellt.

\subsection{Implementation und Tests}

Aufgrund der Ergebnisse der Recherche wurde das Erstellen und Testen des Programmcodes unter den Teammitgliedern aufgeteilt. Zeitgleich erfolgte die Dokumentation der beiden Module, mittels Kommentaren im Programmcode und einer "Readme" Datei. 

\begin{itemize}
\item \textbf{Modul 1: RDFa Parser} \\
Mittels dem npm Modul "cheerio" wird auf Daten eines vorliegenden XHTML Dokuments zugegriffen. Im Anschluss werden mittels der RDFa Core Sequenz und dem npm Modul "rdf", RDF Triple erzeugt \cite{cheerioModule}, \cite{rdfModule}. 

\item \textbf{Modul 2: Webcrawler} \\
Mittels dem npm Modul "simplecrawler" wird, ausgehend von einer vorgegebenen URL und den Benutzereinstellungen, eine Liste von zusammenhängenden URLs erstellt. Dabei wird nach jedem Zugriff auf eine URL Modul 1 aufgerufen. Zu den Benztzereinstellungen z\"ahlt das Black-/Whitelisten, daher die Beschränkung der URL Dom\"anen, sowie die Suchtiefe, L\"ange der Verlinkung ausgehend von der Start URL \cite{simplecrawlerModule}.
\end{itemize}

\subsection{Zusammenf\"uhrung und Publikation}

Im Anschluss wurden die einzelnen Module zusammengeführt und nochmals anhand des "RDFa Test Suite Manifest" getestet, bevor das finale Programm als npm Modul ver\"offentlicht wurde \cite{rdfaTest}.



%------------------------------------------------

\section{Ergebnis}

INSERT: Wie schaut unser Ergebnis aus? Wie nennen wir unser npm Modul?

\subsection{Beispielanwendung}

INSET: README.md

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\renewcommand{\refname}{Referenzen}

\newpage
\bibliography{sample}	% use sample.bib from same absolute path (location)

\bibliographystyle{unsrt}

%----------------------------------------------------------------------------------------

\end{document}